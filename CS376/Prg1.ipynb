{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment we implement a Deep Neural Network\n",
        "Implement from scratch (hence not using NN libraries such as tensor\u001dow,\n",
        "keras, pytorch) a Neural Network that is able to approximate a function of\n",
        "two variables f(x, y). The network will have at least two hidden layers and it\n",
        "is trained using the backpropagation algorithm. The test case we consider is\n",
        "f(x, y) = x · y (we can say that we teach the network to multiply two numbers).\n",
        "As training data for the algorithm construct a matrix of input output triplets\n",
        "of the function f(x, y) = x · y. When x, y ∈ [0, 1] the matrix would contain\n",
        "training triplets of the form [xi\n",
        ", yj , xi\n",
        "· yj ], where xi and yj are random values\n",
        "in [0, 1].\n",
        "Try di\u001berent activation functions and \u001cnd which one performs best with your\n",
        "network. For validation accuracy calculate the root mean square error.\n",
        "Add visualization of the RMSE over training epochs, and perform simple\n",
        "tests to check accuracy."
      ],
      "metadata": {
        "id": "-aFPUv6hSh1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{equation}\n",
        "\\text{standard form}\\\\\n",
        "o_h=\\sum_{l=1}^{10}w_l^4\\phi\\left(\\sum_{k-1}^{10}w_{lk}^3\\phi\\left(\\sum_{j=1}^{10}w_{jk}^2\\phi\\left(\\sum_{i=1}^2w_{ji}^1x_{hi}+b_j^1\\right)+b_k^2\\right)b_l^3\\right)+c\\\\\n",
        "=======================================\\\\\n",
        "\\text{vector form}\\\\\n",
        "o_h=W^4\\phi\\left(W^3\\phi\\left(W^2\\phi\\left(W^1x_h+B^1\\right)+B^2\\right)+B^3\\right)+c\\\\\n",
        "=======================================\\\\\n",
        "W^1\\rightarrow 10\\times2\\\\\n",
        "W^2\\rightarrow 10\\times10\\\\\n",
        "W^3\\rightarrow 10\\times10\\\\\n",
        "W^4\\rightarrow 1\\times10\\\\\n",
        "x_h\\rightarrow 2\\times1\\\\\n",
        "B^1\\rightarrow 10\\times1\\\\\n",
        "B^2\\rightarrow 10\\times1\\\\\n",
        "B^3\\rightarrow 10\\times1\\\\\n",
        "c\\rightarrow \\text{scalar}\\\\\n",
        "o_h\\rightarrow \\text{scalar}\\\\\n",
        "=======================================\\\\\n",
        "o_h=W^4\\phi\\left(W^3\\phi\\left(W^2\\phi\\left((10\\times2)(2\\times1)+(10\\times1)\\right)+B^2\\right)+B^3\\right)+c\\\\\n",
        "o_h=W^4\\phi\\left(W^3\\phi\\left(W^2\\phi\\left(10\\times1\\right)+B^2\\right)+B^3\\right)+c\\\\\n",
        "o_h=W^4\\phi\\left(W^3\\phi\\left((10\\times10)\\left(10\\times1\\right)+(10\\times1)\\right)+B^3\\right)+c\\\\\n",
        "o_h=W^4\\phi\\left((10\\times10)\\left(10\\times1\\right)+(10\\times1)\\right)+c\\\\\n",
        "o_h=(1\\times10)\\left(10\\times1\\right)+c\\\\\n",
        "o_h=\\text{scalar}+\\text{scalar}\\\\\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "EJmWkdjHVi2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the weights\n",
        "W1 # 10x2\n",
        "W2 # 10x10\n",
        "w3 # 10x10\n",
        "W4 # 1x10"
      ],
      "metadata": {
        "id": "1F_Jt9vo59M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the biases\n",
        "b1 # 10x1\n",
        "b2 # 10x1\n",
        "b3 # 10x1\n",
        "c  # scalar"
      ],
      "metadata": {
        "id": "j4URt4-u8jKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96h4cJahSfi-"
      },
      "outputs": [],
      "source": [
        "# build the network\n",
        "\n",
        "# activations\n",
        "import numpy as np\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "# predictions\n",
        "def predict(x):\n",
        "  return W4@sigmoid( W3@sigmoid( W2@sigmoid( W1@x +b1 ) +b2 ) +b3 ) +c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the data\n",
        "  # As training data for the algorithm construct a matrix of input output triplets\n",
        "  # of the function f(x, y) = x · y.\n",
        "  # When x, y ∈ [0, 1] the matrix would contain training triplets of the form [xi , yj , xi · yj ],\n",
        "  # where xi and yj are random values in [0, 1]."
      ],
      "metadata": {
        "id": "5wiw1L-RSyjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the data"
      ],
      "metadata": {
        "id": "PrBki9KIS6Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the network\n",
        "\n",
        "# how are we applying gradient descent and back propogation?\n"
      ],
      "metadata": {
        "id": "NHArQOz-S0Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the network"
      ],
      "metadata": {
        "id": "hJLKkOjuS2f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the test results"
      ],
      "metadata": {
        "id": "1LbHIOSmS8aL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}